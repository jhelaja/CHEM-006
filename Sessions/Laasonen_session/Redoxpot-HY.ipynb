{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project predicting redox potential values \n",
    "\n",
    "data HOMO LUMO energies, fingerprints different combinations of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load SHAP tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  load tools \n",
    "\n",
    "We can load various ML tools in python, in this project most od them come from sklearn\n",
    "SHAP is not in sklearn but you can load it with pip install commend (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import shap\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from sklearn.pipeline import Pipeline\n",
    "print(' load ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir  Re*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "Redox-dataset.csv  : data with descriptors and target (rodoxpot1, 1st redoxpotential)\n",
    "\n",
    "HomoA : HOMO of molec A \n",
    "LumoA : LUMO of molec A \n",
    "GapA  : HOMO-LUMO gap of molec A \n",
    "\n",
    "HomoAH\t:  HOMO of molc AH\n",
    "LumoAH\t:  LUMO of molec AH\n",
    "GapAH\t:  gap of molec AH \n",
    "\n",
    "HomoAH2\t:  same for molc AH2 \n",
    "LumoAH2\t\n",
    "GapAH2\t\n",
    "SIMILES : similes of the molecules\n",
    "\n",
    "finger256.csv : fingerprints (256 different values) of the molecules  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(\"Redox-dataset.csv\")\n",
    "\n",
    "finger_all = pd.read_csv(\"Redox-finger256.csv\")   # 256 fingerp\n",
    "\n",
    "data=data_all.head(2000)       # first 2000, this is more than the data so full data set is used \n",
    "finger=finger_all.head(2000)   # with large data sets it is usefull to use only part of the data for testing \n",
    "                               # and then go the full data\n",
    "\n",
    "print('full data:', data_all.shape)\n",
    "print('working data:', data.shape)\n",
    "\n",
    "# show the data (in python first and last few lines)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create three different datasets:  \n",
    "\n",
    "finger + HOMO-LUMO data\n",
    "\n",
    "finger only \n",
    "\n",
    "Homo-Lumo only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finger\n",
    "redpot=data['redoxpot1']\n",
    "\n",
    "# combine the fingerprints and the other data \n",
    "X2=pd.concat([finger,data],axis=1)   # FP's first\n",
    "\n",
    "# fingerprint and target \n",
    "Xf=pd.concat([finger,redpot],axis=1)   # only FP and target \n",
    "\n",
    "# remove ID redpot2 and SMILES from the data \n",
    "\n",
    "X2=X2.drop(columns= ['ID','redoxpot2','SMILES'])\n",
    "\n",
    "# only the data \n",
    "Xd=data.drop(columns= ['ID','redoxpot2','SMILES'])\n",
    "Target='redoxpot1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the data split for the 3 data sets. Here 25% to the test set \n",
    "\n",
    "y_all = X2[Target]\n",
    "train_data, test_data = train_test_split(X2, test_size=0.25)\n",
    "train_fdata, test_fdata = train_test_split(Xf, test_size=0.25)\n",
    "train_ddata, test_ddata = train_test_split(Xd, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_data.size:',train_data.shape )\n",
    "print('test_data.size:',test_data.shape )\n",
    "print('train_fdata.size:',train_fdata.shape )\n",
    "print('test_fdata.size:',test_fdata.shape )\n",
    "print('train_ddata.size:',train_ddata.shape )\n",
    "print('test_ddata.size:',test_ddata.shape )\n",
    "#testd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head)   # note that the data order has been randomized. This is needed because the original data \n",
    "print(train_fdata.head)  # is usually stored in some prefefined order taht may bias the ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor  Finger and other  (X contain the descriptors and y is the target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns= [Target]) \n",
    "y = train_data[Target]\n",
    "###\n",
    "test_X = test_data.drop(columns= [Target]) \n",
    "#\n",
    "test_y = test_data[Target]\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor  Finger only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = train_fdata.drop(columns= [Target]) # .to_numpy()\n",
    "yf = train_fdata[Target]\n",
    "###\n",
    "test_Xf = test_fdata.drop(columns= [Target]) # .to_numpy()\n",
    "#unscale_tX = test_X\n",
    "test_yf = test_fdata[Target]\n",
    "###\n",
    "print(Xf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = train_ddata.drop(columns= [Target]) # .to_numpy()\n",
    "yd = train_ddata[Target]\n",
    "###\n",
    "test_Xd = test_ddata.drop(columns= [Target]) # .to_numpy()\n",
    "#unscale_tX = test_X\n",
    "test_yd = test_ddata[Target]\n",
    "###\n",
    "print(Xd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose GB, KR or RF the code will do 3 data sets\n",
    "\n",
    "# Which of these methods predict the data best ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ML=\"GB\"\n",
    "\n",
    "if ML==\"GB\":\n",
    "#  # GB method next 2 lines\n",
    "  model = GradientBoostingRegressor()\n",
    "  parameters = {'learning_rate': np.arange(0.05, 0.3, 0.05), \"loss\": ['huber'],\"n_estimators\": range(20, 80, 10),\n",
    "                'subsample': [1.0, 0.9]}   # for GB\n",
    "\n",
    "# learning_rate, loss,  n_estimators and subsample  are thechnical parameters of the GB ML methods. We will find \n",
    "# the best combination of them for this data. This is quite technical and you need to look the manual page of the ML method\n",
    "\n",
    "\n",
    "if ML==\"KR\":\n",
    "  model = KernelRidge()\n",
    "  parameters = {\"alpha\": np.arange(0.5, 3.5, 0.2), \"kernel\": ['linear', 'polynomial', 'laplacian'], \"degree\": [2,3]}  #  KRR\n",
    "\n",
    "if ML==\"RF\":\n",
    "# RF methods next 2 lines\n",
    "  model = RandomForestRegressor()\n",
    "  parameters = {\"n_estimators\": range(110, 190, 20), \"min_samples_split\":[2,3]}  # for RF\n",
    "\n",
    "if ML==\"GP\":\n",
    "# GaussianProc methods next 2 lines. NOTE this will do the fitting here and there is no parameter optimization\n",
    "  kernel = DotProduct() + WhiteKernel()\n",
    "  model = GaussianProcessRegressor(kernel=kernel,random_state=0).fit(X,y)\n",
    "\n",
    "                                                                      \n",
    "# Grid serach will find the best parametetrs cv is the number of cross validation cycles (min cv = 5, 10 is better but slower)\n",
    "###\n",
    "if ML!=\"GP\":\n",
    "  clf = GridSearchCV(model, parameters, cv = 10, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "  clff = GridSearchCV(model, parameters, cv = 10, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "  clfd = GridSearchCV(model, parameters, cv = 10, verbose=2, n_jobs=-1, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the ML method for this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# fit the finger + data desc\n",
    "time0=time()\n",
    "if ML!=\"GP\":\n",
    "  clf.fit(X,y)\n",
    "timee=time()\n",
    "print('time used',timee-time0,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the finger only desc\n",
    "\n",
    "time0=time()\n",
    "if ML!=\"GP\":\n",
    "  clff.fit(Xf,yf)\n",
    "timee=time()\n",
    "print('time used',timee-time0,' s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data only desc\n",
    "time0=time()\n",
    "if ML!=\"GP\":\n",
    "  clfd.fit(Xd,yd)\n",
    "timee=time()\n",
    "print('time used',timee-time0,' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "\n",
    "print(clff.best_params_)\n",
    "\n",
    "print(clfd.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.best_estimator_\n",
    "print(model)\n",
    "modelf = clff.best_estimator_\n",
    "print(modelf)\n",
    "modeld = clfd.best_estimator_\n",
    "print(modeld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The few best models are not very sensitve to the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(clf.cv_results_)\n",
    "result_df = result_df.sort_values(\"rank_test_score\")\n",
    "for i, row in result_df.iterrows():\n",
    "   if(i<10): print(row[\"mean_test_score\"], row[\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  for train data \n",
    "print('===== SHAP FOR TRAIN DATA ====')\n",
    "print('===== NOTE SHAP ANALYSIS DOES NOT WORK WITH KR METHOD ====')\n",
    "smodel=modeld.fit(Xd,yd)      # rather slow\n",
    "explainer = shap.Explainer(smodel)\n",
    "shap_values = explainer(Xd)\n",
    "print('===== SHAP DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Xd.columns\n",
    "\n",
    "featureNames=[]\n",
    "for i in range(0,len(features)-1): # ignore the first and last feature \n",
    "    featureNames.append(features[i])\n",
    "nFeatures=len(featureNames)\n",
    "print('Feature Names ', featureNames)\n",
    "\n",
    "Xs = Xd  # data2   # this have the headers SHAP\n",
    "print('\\n shap base_values ',shap_values.base_values[0])\n",
    "base=shap_values.base_values[0]\n",
    "shap.plots.beeswarm(shap_values,max_display=15) #\n",
    "shap.plots.bar(shap_values) # ,feature_names=featureNames) # all shap values\n",
    "\n",
    "#shap.plots.waterfall(shap_values[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' =========    SHAP 2 ANALYSIS START ========')\n",
    "shap2_values = shap.TreeExplainer(smodel).shap_values(Xd)  # this is slow  X for train data, X2 for all \n",
    "print(' =========    SHAP 2 ANALYSIS DONE ========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "F1=\"HomoAH2\"\n",
    "F2=\"LumoA\"\n",
    "F3=\"GapAH\"\n",
    "F4=\"GapA\"\n",
    "print(' =========    SHAP DEPENDENCE  =============')\n",
    "# shap.dependence_plot(F1, shap2_values, Xd)\n",
    "shap.dependence_plot(F2, shap2_values, Xd)\n",
    "#shap.dependence_plot(F3, shap2_values, Xd)\n",
    "#shap.dependence_plot(F4, shap2_values, Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction analysis. Find  which data set is the best descriptor\n",
    "\n",
    "\n",
    "# FULL fingerprint + data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(X)\n",
    "#print(' shape y',np.shape(y),'shape X',np.shape(X))\n",
    "yy=[]   # y is suffled  yy contain the unsuffled data\n",
    "i=0\n",
    "for yp in y:\n",
    "#  print('test y  ',i,yp)\n",
    "  yy.append(yp)\n",
    "  i+=1\n",
    "print(' shape y',np.shape(y),'shape X',np.shape(X))\n",
    "\n",
    "cut=0.25\n",
    "print('\\n------------Test large deviations --(cut >',cut,')-------------')\n",
    "for ii in range(len(y)):\n",
    "    if abs(pred_y[ii]-yy[ii]) > cut:\n",
    "      print('Pred E ',pred_y[ii],' E_DFT',yy[ii],'diff',abs(pred_y[ii]-yy[ii]))\n",
    "\n",
    "print('---------------------------------------------------------------')\n",
    "\n",
    "plt.plot(pred_y, y, 'o', label = \"ML\")\n",
    "plt.plot(y, y)\n",
    "plt.xlabel(\"Predicted Energy (eV)\")\n",
    "plt.ylabel(\"DFT energy (eV)\")\n",
    "plt.legend()\n",
    "r_sqrt = r2_score(y, pred_y)\n",
    "e_mse = mse(y,pred_y)  # Mean squared error \n",
    "e_mae = mae(y,pred_y)  # Mean abs error \n",
    "print(\"\\n R^2 on ML training set:\", r_sqrt)\n",
    "print(\" MSE on ML training set:\", e_mse)\n",
    "print(\" MAE on ML training set:\", e_mae)\n",
    "\n",
    "# you can save the r2, MSE and MAE values \n",
    "\n",
    "if(ML==\"GB\"):\n",
    "    GB_r2_full=r_sqrt\n",
    "    GB_MSE_full=e_mse\n",
    "    GB_MAE_full=e_mae\n",
    "    \n",
    "if(ML==\"KR\"):\n",
    "    KR_r2_full=r_sqrt\n",
    "    KR_MSE_full=e_mse\n",
    "    KR_MAE_full=e_mae\n",
    "\n",
    "if(ML==\"RF\"):\n",
    "    RF_r2_full=r_sqrt\n",
    "    RF_MSE_full=e_mse\n",
    "    RF_MAE_full=e_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finager print only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' FINGERPRINT ONLY \\n')\n",
    "pred_yf = modelf.predict(Xf)\n",
    "#print(' shape y',np.shape(y),'shape X',np.shape(X))\n",
    "yy=[]   # y is suffled  yy contain the unsuffled data\n",
    "i=0\n",
    "for yp in yf:\n",
    "#  print('test y  ',i,yp)\n",
    "  yy.append(yp)\n",
    "  i+=1\n",
    "#print('y(0:18) \\n',y[0:8],yy[0:8])\n",
    "print(' shape y',np.shape(y),'shape X',np.shape(X))\n",
    "\n",
    "cut=0.25\n",
    "print('\\n------------Test large deviations --(cut >',cut,')-------------')\n",
    "for ii in range(len(y)):\n",
    "    if abs(pred_yf[ii]-yy[ii]) > cut:\n",
    "#      print('Xii, i',ii,X[ii,:])\n",
    "#       Xtest=X[ii,:].reshape(1, -1) \n",
    "#       model.predict(Xtest)\n",
    "      print('Pred E ',pred_yf[ii],' E_DFT',yy[ii],'diff',abs(pred_yf[ii]-yy[ii]))\n",
    "\n",
    "print('---------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot(pred_yf, yf, 'o', label = \"ML\")\n",
    "plt.plot(yf, yf)\n",
    "plt.xlabel(\"Predicted Energy (eV)\")\n",
    "plt.ylabel(\"DFT energy (eV)\")\n",
    "plt.legend()\n",
    "r_sqrt = r2_score(yf, pred_yf)\n",
    "e_mse = mse(yf,pred_yf)  # Mean squared error \n",
    "e_mae = mae(yf,pred_yf)  # Mean abs error \n",
    "print(\"\\n R^2 on ML training set:\", r_sqrt)\n",
    "print(\" MSE on ML training set:\", e_mse)\n",
    "print(\" MAE on ML training set:\", e_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' HOMO LUMO DATA ONLY \\n')\n",
    "pred_yd = modeld.predict(Xd)\n",
    "#print(' shape y',np.shape(y),'shape X',np.shape(X))\n",
    "yy=[]   # y is suffled  yy contain the unsuffled data\n",
    "i=0\n",
    "for yp in yd:\n",
    "#  print('test y  ',i,yp)\n",
    "  yy.append(yp)\n",
    "  i+=1\n",
    "# print('y(0:18) \\n',y[0:8],yy[0:8])\n",
    "print(' shape y',np.shape(y),'shape X',np.shape(X))\n",
    "\n",
    "cut=0.25\n",
    "print('\\n------------Test large deviations --(cut >',cut,')-------------')\n",
    "for ii in range(len(y)):\n",
    "    if abs(pred_yd[ii]-yy[ii]) > cut:\n",
    "      print('Pred E ',pred_yf[ii],' E_DFT',yy[ii],'diff',abs(pred_yf[ii]-yy[ii]))\n",
    "\n",
    "print('---------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot(pred_yd, yd, 'o', label = \"ML\")\n",
    "plt.plot(yd, yd)\n",
    "plt.xlabel(\"Predicted Energy (eV)\")\n",
    "plt.ylabel(\"DFT energy (eV)\")\n",
    "plt.legend()\n",
    "r_sqrt = r2_score(yd, pred_yd)\n",
    "e_mse = mse(yd,pred_yd)  # Mean squared error \n",
    "e_mae = mae(yd,pred_yd)  # Mean abs error \n",
    "print(\"\\n R^2 on ML training set:\", r_sqrt)\n",
    "print(\" MSE on ML training set:\", e_mse)\n",
    "print(\" MAE on ML training set:\", e_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_X = test_data.drop(columns= ['dEf', 'name']).to_numpy()\n",
    "#test_y = test_data['dEf']\n",
    "print(' FULL data Test set \\n') \n",
    "print(' shape y',np.shape(test_y),'shape X',np.shape(test_X))\n",
    "predt_y = model.predict(test_X)\n",
    "\n",
    "yy=[]   # test_y is suffled  yy is the unsuffled data\n",
    "i=0\n",
    "for yp in test_y:\n",
    "#  print('test y  ',i,yp)\n",
    "  yy.append(yp)\n",
    "  i+=1\n",
    "\n",
    "cut=0.3\n",
    "print('\\n------------Test large deviations --(cut >',cut,')-------------')\n",
    "for ii in range(len(test_y)):\n",
    "    if abs(predt_y[ii]-yy[ii]) > cut:\n",
    "#      print('test_X, i',ii,test_X[ii,:])\n",
    "#       Xtest=X[ii,:].reshape(1, -1) \n",
    "      print('Pred E ',predt_y[ii],' E_DFT',yy[ii],'diff',abs(predt_y[ii]-yy[ii]))\n",
    "print('-----------------------------------------------------------------')\n",
    "r_sqrt = r2_score(test_y, predt_y)\n",
    "e_mse = mse(test_y,predt_y)  # Mean squared error \n",
    "e_mae = mae(test_y,predt_y)  # Mean abs error \n",
    "print(\"\\n R^2 on ML TEST set:\", r_sqrt)\n",
    "print(\" MSE on ML TEST set:\", e_mse)\n",
    "print(\" MAE on ML TEST set:\", e_mae)\n",
    "\n",
    "plt.plot(predt_y, test_y, 'o', label = \"ML\")\n",
    "plt.plot(test_y, test_y)\n",
    "plt.xlabel(\"Predicted redox (eV)\")\n",
    "plt.ylabel(\"DFT redox (eV)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal importance analysis\n",
    "\n",
    "feature_importance = modeld.feature_importances_\n",
    "data_used = train_ddata.drop(columns= [Target])\n",
    "plt.bar(data_used.columns, feature_importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
